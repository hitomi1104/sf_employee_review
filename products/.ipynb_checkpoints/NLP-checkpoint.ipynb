{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564da53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import warnings\n",
    "import streamlit as st\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5e163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "import re,string,unicodedata\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8ab1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_cleaned_translated_dummified.csv')\n",
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc4bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topic', 'usage situation', 'type of business', 'review date',\n",
       "       'overall rating', 'review', 'number of accounts used',\n",
       "       'effects after introducing the service', 'rate ease of use',\n",
       "       'rate helpfulness', 'rate customizability',\n",
       "       'rate functional satisfaction', 'rate service stability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64e2e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>topic</th>\n",
       "      <th>usage situation</th>\n",
       "      <th>type of business</th>\n",
       "      <th>review date</th>\n",
       "      <th>overall rating</th>\n",
       "      <th>review</th>\n",
       "      <th>number of accounts used</th>\n",
       "      <th>effects after introducing the service</th>\n",
       "      <th>rate ease of use</th>\n",
       "      <th>rate helpfulness</th>\n",
       "      <th>rate customizability</th>\n",
       "      <th>rate functional satisfaction</th>\n",
       "      <th>rate service stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Great job on customer support</td>\n",
       "      <td>using</td>\n",
       "      <td>Consulting Service</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>4</td>\n",
       "      <td>You can manage the history of previous interac...</td>\n",
       "      <td>&gt;201-300</td>\n",
       "      <td>In the past, sales management and personnel ma...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>You can share customer management in one app.</td>\n",
       "      <td>using</td>\n",
       "      <td>IT related Service</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>5</td>\n",
       "      <td>By collectively managing internal customer inf...</td>\n",
       "      <td>&gt;51-100</td>\n",
       "      <td>Conversations, reactions and characteristics w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          topic usage situation  \\\n",
       "0           0                  Great job on customer support           using   \n",
       "1           1  You can share customer management in one app.           using   \n",
       "\n",
       "     type of business review date  overall rating  \\\n",
       "0  Consulting Service  2022-07-28               4   \n",
       "1  IT related Service  2022-07-28               5   \n",
       "\n",
       "                                              review number of accounts used  \\\n",
       "0  You can manage the history of previous interac...                >201-300   \n",
       "1  By collectively managing internal customer inf...                 >51-100   \n",
       "\n",
       "               effects after introducing the service  rate ease of use  \\\n",
       "0  In the past, sales management and personnel ma...               4.0   \n",
       "1  Conversations, reactions and characteristics w...               4.0   \n",
       "\n",
       "   rate helpfulness  rate customizability  rate functional satisfaction  \\\n",
       "0               4.0                   4.0                           4.0   \n",
       "1               4.0                   5.0                           5.0   \n",
       "\n",
       "   rate service stability  \n",
       "0                     4.0  \n",
       "1                     4.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b0a07",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f439b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22db3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['topic']=df['topic'].apply(remove_special_characters)\n",
    "df['review']=df['review'].apply(remove_special_characters)\n",
    "df['effects after introducing the service']=df['effects after introducing the service'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2879dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "\n",
    "df['topic']=df['topic'].apply(lemmatize_text)\n",
    "df['review']=df['review'].apply(lemmatize_text)\n",
    "df['effects after introducing the service']=df['effects after introducing the service'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1104df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'didn', 'its', 'again', 'me', 'but', 'don', 'now', 'through', \"isn't\", 'won', 'off', 'down', \"aren't\", 'why', 'here', 'only', 'himself', 'by', 'hasn', 'nor', 'he', \"you're\", 'then', 'between', 'you', 'has', \"hasn't\", 'very', 'too', 'does', 'she', 'on', 'am', 'i', 'couldn', 'shan', \"you'll\", 'both', 'where', \"weren't\", 'my', 'over', 'the', 'they', 'those', 'mustn', 'wasn', 'your', 'who', 'if', \"needn't\", \"wasn't\", 'as', \"mightn't\", 'before', 'theirs', 'should', 'other', 'just', 'ourselves', 'below', 'until', \"she's\", 'll', 'yours', 'during', 'more', 'all', 'be', 'having', 'haven', 'than', 'hers', 'weren', 'a', 'ain', \"doesn't\", 'once', \"won't\", 're', 'myself', 'did', 'and', 'themselves', 'in', \"shouldn't\", 'our', 'these', 'doing', 'needn', 'to', 'each', 'few', 'no', 'mightn', 'after', \"wouldn't\", 'them', \"couldn't\", 'most', 'some', 'ours', 'aren', 'it', 'whom', 'so', \"don't\", 'have', 'had', 'not', \"shan't\", 'are', 'against', 'm', 'is', 'further', 'out', \"hadn't\", 'her', 'while', 'do', 'above', 'this', 'hadn', 'yourself', 'd', 'such', 'o', \"you'd\", 'how', 'isn', \"mustn't\", 'him', \"you've\", \"didn't\", 'wouldn', \"it's\", 'which', 'there', 'been', 'into', 've', 't', 'when', 'that', 'own', 'with', \"haven't\", 'an', 'from', 'up', 's', \"should've\", 'at', 'same', 'y', 'or', 'shouldn', 'will', 'herself', \"that'll\", 'because', 'itself', 'we', 'ma', 'any', 'their', 'were', 'his', 'for', 'doesn', 'under', 'can', 'what', 'of', 'was', 'being', 'about', 'yourselves'}\n"
     ]
    }
   ],
   "source": [
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "df['topic']=df['topic'].apply(remove_stopwords)\n",
    "df['review']=df['review'].apply(remove_stopwords)\n",
    "df['effects after introducing the service']=df['effects after introducing the service'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bd207",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39177143",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "tf.fit(df['topic'])\n",
    "\n",
    "pro_tf = tf.transform(df[''])\n",
    "pro_df = pd.DataFrame(pro_tf.todense(), columns=tf.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,30))\n",
    "top_texts = pro_df.sum().sort_values(ascending=False)\n",
    "top_texts.head(100).plot(kind='barh')\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b52f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b70a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7ef98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97666f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d380840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9540e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933924e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

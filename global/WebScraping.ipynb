{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e705e55",
   "metadata": {},
   "source": [
    "https://bulletbyte.weebly.com/tech/how-to-scrape-a-companys-glassdoor-reviews-using-python\n",
    "\n",
    "https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ded2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4923e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to scrape any Glassdoor company review page\n",
    "#the code still works when I run it on 7 Sep, 2021, but the html content of Glassdoor webpages changes all the time\n",
    "#please inspect the webpage and make the necessary changes to the html tags if any of the list returns empty\n",
    "\n",
    "def review_scraper(url):\n",
    "  #scraping the web page content\n",
    "  hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "  req = Request(url,headers=hdr)\n",
    "  page = urlopen(req)\n",
    "  soup = BeautifulSoup(page, \"html.parser\") \n",
    "\n",
    "  #define some lists\n",
    "  Summary=[]\n",
    "  Date_n_JobTitle=[]\n",
    "  Date=[]\n",
    "  JobTitle=[]\n",
    "  AuthorLocation=[]\n",
    "  OverallRating=[]\n",
    "  Pros=[]\n",
    "  Cons=[]  \n",
    "\n",
    "  #get the Summary\n",
    "  for x in soup.find_all('h2', {'class':'mb-xxsm mt-0 css-93svrw el6ke055'}):\n",
    "    Summary.append(x.text)\n",
    "\n",
    "  #get the Posted Date and Job Title\n",
    "  for x in soup.find_all('span', {'class':'middle common__EiReviewDetailsStyle__newGrey'}):\n",
    "    Date_n_JobTitle.append(x.text)\n",
    "\n",
    "  #get the Posted Date\n",
    "  for x in Date_n_JobTitle:\n",
    "    Date.append(x.split(' -')[0])\n",
    "\n",
    "  #get Job Title\n",
    "  for x in Date_n_JobTitle:\n",
    "    JobTitle.append(x.split(' -')[1])\n",
    "\n",
    "  #get Author Location\n",
    "  for x in soup.find_all('span', {'class':'middle'}):\n",
    "    AuthorLocation.append(x.text)\n",
    "\n",
    "  #get Overall Rating\n",
    "  for x in soup.find_all('span', {'class':'ratingNumber mr-xsm'}):\n",
    "    OverallRating.append(float(x.text))\n",
    "\n",
    "  #get Pros\n",
    "  for x in soup.find_all('span', {'data-test':'pros'}):\n",
    "    Pros.append(x.text)\n",
    "\n",
    "  #get Cons\n",
    "  for x in soup.find_all('span', {'data-test':'cons'}):\n",
    "    Cons.append(x.text)\n",
    "\n",
    "  #putting everything together\n",
    "  Reviews = pd.DataFrame(list(zip(Summary, Date, JobTitle, AuthorLocation, OverallRating, Pros, Cons)), \n",
    "                    columns = ['Summary', 'Date', 'JobTitle', 'AuthorLocation', 'OverallRating', 'Pros', 'Cons'])\n",
    "  \n",
    "  return Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84b814",
   "metadata": {},
   "source": [
    "<h2 class=\"mb-xxsm mt-0 css-93svrw el6ke055\"><a href=\"/Reviews/Employee-Review-Salesforce-RVW51057878.htm\" class=\"reviewLink\">Amazing!</a></h2>\n",
    "<span class=\"middle common__EiReviewDetailsStyle__newGrey\">Nov 30, 2020 - Account Executive- Core Team</span>\n",
    "<span class=\"middle\">in <span>San Francisco, CA</span></span>\n",
    "<span class=\"ratingNumber mr-xsm\">3.0</span>\n",
    "<span data-test=\"pros\">- Benefits are top notch\n",
    "- Perks in the tower and holiday party are impressive\n",
    "- Sales tactics and strategies are great for growth even as an experienced rep\n",
    "- Youâ€™ll meet very talented sales rep with a wide variance of styles\n",
    "-ESPP\n",
    "- generous maternity/paternity leave. Although this will affect your likelihood of be promoted</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69705101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159   .htm\n",
    "# https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159   _P2.htm?filter.iso3Language=eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7cb70e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m maxPage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# maxPage = 1770 + 1\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#uncomment the line below to set the max page to scrape (based on total number of reviews)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#maxPage = countPages + 1\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#scraping multiple pages of company glassdoor review\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# output = review_scraper(input_url+str(1)+\".htm?sort.sortType=RD&sort.ascending=false\")\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m output \u001b[38;5;241m=\u001b[39m review_scraper(input_url\u001b[38;5;241m+\u001b[39m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.htm?filter.iso3Language=eng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,maxPage):\n\u001b[1;32m     32\u001b[0m     url \u001b[38;5;241m=\u001b[39m input_url\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_P\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtm?filter.iso3Language=eng\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'str'"
     ]
    }
   ],
   "source": [
    "#paste/replace the url to the first page of the company's Glassdoor review in between the \"\"\n",
    "\n",
    "\n",
    "input_url=\"https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159\"\n",
    "# https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159_P3.htm?filter.iso3Language=eng\n",
    "\n",
    "#scraping the first page content\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(input_url+\".htm\",headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"html.parser\") \n",
    "\n",
    "#check the total number of reviews\n",
    "countReviews = soup.find('div', {'data-test':'pagination-footer-text'}).text\n",
    "countReviews = float(countReviews.split(' Reviews')[0].split('of ')[1].replace(',',''))\n",
    "\n",
    "#calculate the max number of pages (assuming 10 reviews a page)\n",
    "countPages = math.ceil(countReviews/10)\n",
    "countPages\n",
    "\n",
    "#I'm setting the max pages to scrape to 3 here to save time\n",
    "maxPage = 3 + 1\n",
    "# maxPage = 1770 + 1\n",
    "#uncomment the line below to set the max page to scrape (based on total number of reviews)\n",
    "#maxPage = countPages + 1\n",
    "\n",
    "#scraping multiple pages of company glassdoor review\n",
    "# output = review_scraper(input_url+str(1)+\".htm?sort.sortType=RD&sort.ascending=false\")\n",
    "output = review_scraper(input_url++str(1)+\".htm?filter.iso3Language=eng\")\n",
    "\n",
    "for x in range(2,maxPage):\n",
    "    url = input_url+\"_P\"+str(x)+\"htm?filter.iso3Language=eng\"\n",
    "    output = output.append(review_scraper(url), ignore_index=True)\n",
    "    print(x)\n",
    "#     time.sleep(1)\n",
    "\n",
    "#display the output\n",
    "display(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9835d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b88284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44420df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import warnings\n",
    "import streamlit as st\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "# folium\n",
    "import folium\n",
    "import folium.plugins as plugins\n",
    "from streamlit_folium import folium_static\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "\n",
    "# this line tells jupyter notebook to put the plots in the notebook rather than saving them to file\n",
    "%matplotlib inline\n",
    "\n",
    "# this line makes plots prettier on mac retina screens - if you don't have one it shouldn't do anything\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "# Style\n",
    "sns.set_style(style = 'darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0723fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "df.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778134ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7eedd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['OverallRating','Cons']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c918c7",
   "metadata": {},
   "source": [
    "# Cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ed9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549da907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "import re,string,unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccad96e",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bec1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75b28a",
   "metadata": {},
   "source": [
    "### Removing special chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['Cons']=df['Cons'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d86b4",
   "metadata": {},
   "source": [
    "### Text stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stemming the text\n",
    "# def simple_stemmer(text):\n",
    "#     ps=nltk.porter.PorterStemmer()\n",
    "#     text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "#     return text\n",
    "# #Apply function on review column\n",
    "# df['Cons']=df['Cons'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605a6eb",
   "metadata": {},
   "source": [
    "### Text Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "\n",
    "#Apply function on review column\n",
    "df['Cons']=df['Cons'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594e695",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "df['Pros']=df['Pros'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c9b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186fc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25067af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "tf.fit(df['Pros'])\n",
    "\n",
    "pro_tf = tf.transform(df['Pros'])\n",
    "pro_df = pd.DataFrame(pro_tf.todense(), columns=tf.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,30))\n",
    "top_texts = pro_df.sum().sort_values(ascending=False)\n",
    "top_texts.head(100).plot(kind='barh')\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e632ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "# Create and generate a word cloud image:\n",
    "Cloud = WordCloud(width=1000, height=700,\n",
    "                  background_color='black',\n",
    "                  stopwords=stopwords,\n",
    "                  min_font_size=3,\n",
    "                  min_word_length=0).generate_from_frequencies(top_texts.head(100))\n",
    "\n",
    "# background_color=\"white\", max_words=50).generate_from_frequencies(top_texts)\n",
    "\n",
    "# Display the generated image:\n",
    "# plt.figure(figsize=(15,10))\n",
    "plt.imshow(Cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a2896",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words='english', min_df=3, ngram_range=(2,2))\n",
    "tf.fit(df['Pros'])\n",
    "\n",
    "pro_tf = tf.transform(df['Pros'])\n",
    "pro_df = pd.DataFrame(pro_tf.todense(), columns=tf.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,30))\n",
    "top_texts = pro_df.sum().sort_values(ascending=False)\n",
    "top_texts.head(100).plot(kind='barh')\n",
    "print(fig)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Create and generate a word cloud image:\n",
    "Cloud = WordCloud(width=500, height=400,\n",
    "                  background_color='black',\n",
    "                  stopwords=stopwords,\n",
    "                  min_font_size=3,\n",
    "                  min_word_length=0).generate_from_frequencies(top_texts)\n",
    "\n",
    "# background_color=\"white\", max_words=50).generate_from_frequencies(top_texts)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(Cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words='english', min_df=3, ngram_range=(3,3))\n",
    "tf.fit(df['Pros'])\n",
    "\n",
    "pro_tf = tf.transform(df['Pros'])\n",
    "pro_df = pd.DataFrame(pro_tf.todense(), columns=tf.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,30))\n",
    "top_texts = pro_df.sum().sort_values(ascending=False)\n",
    "top_texts.head(100).plot(kind='barh')\n",
    "print(fig)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Create and generate a word cloud image:\n",
    "Cloud = WordCloud(width=500, height=400,\n",
    "                  background_color='black',\n",
    "                  stopwords=stopwords,\n",
    "                  min_font_size=3,\n",
    "                  min_word_length=0).generate_from_frequencies(top_texts)\n",
    "\n",
    "# background_color=\"white\", max_words=50).generate_from_frequencies(top_texts)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(Cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7ea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c79267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c1947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9df62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd6ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd04a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74534fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da4ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
